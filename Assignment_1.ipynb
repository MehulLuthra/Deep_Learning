{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-3ZCXmrqhb0",
        "outputId": "fe8c3dd8-7dff-4a22-d600-e679c7d4e8cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "========================\n",
            "Training for AND gate\n",
            "========================\n",
            "Final Weights: w1 = 0.20, w2 = 0.10\n",
            "Final Bias: b = -0.20\n",
            "Predictions:\n",
            "Input (0, 0) → Predicted: 0, Actual: 0\n",
            "Input (0, 1) → Predicted: 0, Actual: 0\n",
            "Input (1, 0) → Predicted: 0, Actual: 0\n",
            "Input (1, 1) → Predicted: 1, Actual: 1\n",
            "\n",
            "========================\n",
            "Training for OR gate\n",
            "========================\n",
            "Final Weights: w1 = 0.10, w2 = 0.10\n",
            "Final Bias: b = -0.10\n",
            "Predictions:\n",
            "Input (0, 0) → Predicted: 0, Actual: 0\n",
            "Input (0, 1) → Predicted: 1, Actual: 1\n",
            "Input (1, 0) → Predicted: 1, Actual: 1\n",
            "Input (1, 1) → Predicted: 1, Actual: 1\n",
            "\n",
            "========================\n",
            "Training for NAND gate\n",
            "========================\n",
            "Final Weights: w1 = -0.20, w2 = -0.10\n",
            "Final Bias: b = 0.20\n",
            "Predictions:\n",
            "Input (0, 0) → Predicted: 1, Actual: 1\n",
            "Input (0, 1) → Predicted: 1, Actual: 1\n",
            "Input (1, 0) → Predicted: 1, Actual: 1\n",
            "Input (1, 1) → Predicted: 0, Actual: 0\n",
            "\n",
            "========================\n",
            "Training for NOR gate\n",
            "========================\n",
            "Final Weights: w1 = -0.10, w2 = -0.10\n",
            "Final Bias: b = 0.00\n",
            "Predictions:\n",
            "Input (0, 0) → Predicted: 1, Actual: 1\n",
            "Input (0, 1) → Predicted: 0, Actual: 0\n",
            "Input (1, 0) → Predicted: 0, Actual: 0\n",
            "Input (1, 1) → Predicted: 0, Actual: 0\n",
            "\n",
            "========================\n",
            "Training for XOR gate\n",
            "========================\n",
            "Final Weights: w1 = -0.10, w2 = 0.00\n",
            "Final Bias: b = 0.00\n",
            "Predictions:\n",
            "Input (0, 0) → Predicted: 1, Actual: 0\n",
            "Input (0, 1) → Predicted: 1, Actual: 1\n",
            "Input (1, 0) → Predicted: 0, Actual: 1\n",
            "Input (1, 1) → Predicted: 0, Actual: 0\n"
          ]
        }
      ],
      "source": [
        "# =====================================\n",
        "# Perceptron from scratch (UCS761 Lab 1)\n",
        "# =====================================\n",
        "\n",
        "# Input combinations (fixed for all gates)\n",
        "X = [(0,0), (0,1), (1,0), (1,1)]\n",
        "\n",
        "# Logic gate labels (ONLY Y CHANGES)\n",
        "gates = {\n",
        "    \"AND\"  : [0, 0, 0, 1],\n",
        "    \"OR\"   : [0, 1, 1, 1],\n",
        "    \"NAND\" : [1, 1, 1, 0],\n",
        "    \"NOR\"  : [1, 0, 0, 0],\n",
        "    \"XOR\"  : [0, 1, 1, 0]\n",
        "}\n",
        "\n",
        "# Perceptron parameters\n",
        "lr = 0.1\n",
        "epochs = 20\n",
        "\n",
        "# Training function (WRITTEN ONCE)\n",
        "def train_perceptron(X, Y, lr, epochs):\n",
        "    # Initialize weights and bias\n",
        "    w1, w2, b = 0.0, 0.0, 0.0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for (x1, x2), y in zip(X, Y):\n",
        "            z = w1*x1 + w2*x2 + b\n",
        "            y_hat = 1 if z >= 0 else 0\n",
        "            error = y - y_hat\n",
        "\n",
        "            # Update only if mistake\n",
        "            w1 += lr * error * x1\n",
        "            w2 += lr * error * x2\n",
        "            b  += lr * error\n",
        "\n",
        "    return w1, w2, b\n",
        "\n",
        "# Prediction function\n",
        "def predict(X, w1, w2, b):\n",
        "    predictions = []\n",
        "    for x1, x2 in X:\n",
        "        z = w1*x1 + w2*x2 + b\n",
        "        y_hat = 1 if z >= 0 else 0\n",
        "        predictions.append(y_hat)\n",
        "    return predictions\n",
        "\n",
        "\n",
        "# ==========================\n",
        "# Run for all logic gates\n",
        "# ==========================\n",
        "for gate, Y in gates.items():\n",
        "    print(\"\\n========================\")\n",
        "    print(f\"Training for {gate} gate\")\n",
        "    print(\"========================\")\n",
        "\n",
        "    w1, w2, b = train_perceptron(X, Y, lr, epochs)\n",
        "    preds = predict(X, w1, w2, b)\n",
        "\n",
        "    print(f\"Final Weights: w1 = {w1:.2f}, w2 = {w2:.2f}\")\n",
        "    print(f\"Final Bias: b = {b:.2f}\")\n",
        "    print(\"Predictions:\")\n",
        "\n",
        "    for inp, pred, actual in zip(X, preds, Y):\n",
        "        print(f\"Input {inp} → Predicted: {pred}, Actual: {actual}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BFKIqbS8sAaH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}